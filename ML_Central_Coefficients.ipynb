{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0704f056-8ac6-4b80-a1fc-e272491edaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 5365\n",
      "Feature vector size: 300\n",
      "Best KNN Parameters: {'n_neighbors': 9}\n",
      "Confusion Matrix:\n",
      "[[486  86]\n",
      " [337 164]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.85      0.70       572\n",
      "           1       0.66      0.33      0.44       501\n",
      "\n",
      "    accuracy                           0.61      1073\n",
      "   macro avg       0.62      0.59      0.57      1073\n",
      "weighted avg       0.62      0.61      0.58      1073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from skimage import io\n",
    "from pywt import dwt2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def get_center_coefficients(matrix, block_size=10):\n",
    "    \"\"\"\n",
    "    Extracts a central square block from the matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - matrix (np.ndarray): The input 2D matrix.\n",
    "    - block_size (int): The size of the central block (block_size x block_size).\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Flattened central coefficients.\n",
    "    \"\"\"\n",
    "    center_x, center_y = matrix.shape[0] // 2, matrix.shape[1] // 2\n",
    "    half_size = block_size // 2\n",
    "    \n",
    "    # Handle even and odd block sizes\n",
    "    if block_size % 2 == 0:\n",
    "        start_x = center_x - half_size\n",
    "        start_y = center_y - half_size\n",
    "    else:\n",
    "        start_x = center_x - half_size\n",
    "        start_y = center_y - half_size\n",
    "    \n",
    "    # Ensure indices are within matrix bounds\n",
    "    start_x = max(start_x, 0)\n",
    "    start_y = max(start_y, 0)\n",
    "    end_x = start_x + block_size\n",
    "    end_y = start_y + block_size\n",
    "    \n",
    "    # Extract the central block\n",
    "    central_block = matrix[start_x:end_x, start_y:end_y]\n",
    "    \n",
    "    # If the extracted block is smaller than desired (due to matrix edges), pad with zeros\n",
    "    if central_block.shape[0] != block_size or central_block.shape[1] != block_size:\n",
    "        central_block = np.pad(central_block, \n",
    "                                ((0, max(block_size - central_block.shape[0], 0)),\n",
    "                                 (0, max(block_size - central_block.shape[1], 0))),\n",
    "                                mode='constant', constant_values=0)\n",
    "    \n",
    "    return central_block.flatten()\n",
    "\n",
    "def extract_features(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # DCT\n",
    "    dct_matrix = cv2.dct(np.float32(gray) / 255.0)\n",
    "    dct_features = get_center_coefficients(dct_matrix, block_size=10)  # 10x10 block -> 100 coefficients\n",
    "    \n",
    "    # Wavelet Transform\n",
    "    coeffs2 = dwt2(gray, 'haar')\n",
    "    cA, (cH, cV, cD) = coeffs2\n",
    "    wavelet_features = np.concatenate([cA.flatten(), cH.flatten(), cV.flatten(), cD.flatten()])[:100]\n",
    "        \n",
    "    # FFT\n",
    "    fft_matrix = np.fft.fftshift(np.fft.fft2(gray))\n",
    "    magnitude_spectrum = 20 * np.log(np.abs(fft_matrix) + 1e-10)  # To avoid log(0)\n",
    "    fft_features = get_center_coefficients(magnitude_spectrum, block_size=10)  # 10x10 block -> 100 coefficients\n",
    "    \n",
    "    # Combine features\n",
    "    features = np.concatenate([dct_features, wavelet_features, fft_features])\n",
    "    \n",
    "    # Check for NaN or infinite values\n",
    "    if np.any(np.isnan(features)) or np.any(np.isinf(features)):\n",
    "        return None  # Return None for invalid features\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Load dataset\n",
    "def load_data(base_path):\n",
    "    features, labels = [], []\n",
    "    for label in ['real', 'fake']:\n",
    "        folder_path = os.path.join(base_path, label)\n",
    "        for image_name in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            # Ensure the image was read correctly\n",
    "            if image is None:\n",
    "                print(f\"Warning: Unable to read image {image_path}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            feature_vector = extract_features(image)\n",
    "            if feature_vector is not None:  # Only append valid feature vectors\n",
    "                features.append(feature_vector)\n",
    "                labels.append(0 if label == 'real' else 1)  # 0 for real, 1 for fake\n",
    "            else:\n",
    "                print(f\"Warning: Invalid features for image {image_path}. Skipping.\")\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Prepare data\n",
    "base_path = r\"C:\\Desktop\\ML_Implementation\\data(Final_ML)\\train\"\n",
    "X, y = load_data(base_path)\n",
    "\n",
    "print(f\"Total samples: {X.shape[0]}\")\n",
    "print(f\"Feature vector size: {X.shape[1]}\")\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Example: Train a K-Nearest Neighbors classifier with GridSearchCV\n",
    "param_grid = {'n_neighbors': list(range(1, 31))}\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator\n",
    "best_knn = grid_search.best_estimator_\n",
    "print(f\"Best KNN Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec694114-1fd3-4c13-8962-c5a01c9edf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[394 178]\n",
      " [264 237]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.69      0.64       572\n",
      "           1       0.57      0.47      0.52       501\n",
      "\n",
      "    accuracy                           0.59      1073\n",
      "   macro avg       0.58      0.58      0.58      1073\n",
      "weighted avg       0.59      0.59      0.58      1073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#perceptron Implementation\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # Training\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                y_predicted = self._activation_function(linear_output)\n",
    "                # Update rule\n",
    "                update = self.lr * (y[idx] - y_predicted)\n",
    "                self.weights += update * x_i\n",
    "                self.bias += update\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self._activation_function(linear_output)\n",
    "        return y_predicted\n",
    "\n",
    "    def _activation_function(self, x):\n",
    "        return np.where(x >= 0, 1, 0)  # Step activation function\n",
    "\n",
    "# Initialize and train the Perceptron\n",
    "perceptron = Perceptron(learning_rate=0.01, n_iters=1000)\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55fa0fb-8185-4ba3-bfe3-3f2153de9834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.64144354 0.63213038 0.63053613 0.63636364 0.6025641 ]\n",
      "Mean CV score: 0.6286075585260684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67       572\n",
      "           1       0.62      0.58      0.60       501\n",
      "\n",
      "    accuracy                           0.64      1073\n",
      "   macro avg       0.63      0.63      0.63      1073\n",
      "weighted avg       0.64      0.64      0.64      1073\n",
      "\n",
      "[[394 178]\n",
      " [212 289]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Initialize the Decision Tree Classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(decision_tree, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV score: {np.mean(cv_scores)}\")\n",
    "\n",
    "# Fit the model on the training data\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Performance Metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce20f0d-9a29-4ee7-8ff3-e563ad2256bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[452 120]\n",
      " [133 368]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       572\n",
      "           1       0.75      0.73      0.74       501\n",
      "\n",
      "    accuracy                           0.76      1073\n",
      "   macro avg       0.76      0.76      0.76      1073\n",
      "weighted avg       0.76      0.76      0.76      1073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Initialize the Random Forest Classifier with chosen parameters\n",
    "random_forest = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ca18f34-b3c8-4cdf-b488-32417784ceea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[467 105]\n",
      " [141 360]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79       572\n",
      "           1       0.77      0.72      0.75       501\n",
      "\n",
      "    accuracy                           0.77      1073\n",
      "   macro avg       0.77      0.77      0.77      1073\n",
      "weighted avg       0.77      0.77      0.77      1073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "# Initialize the CatBoost Classifier\n",
    "catboost_model = CatBoostClassifier(iterations=1000, depth=6, learning_rate=0.1, random_seed=42, verbose=0)\n",
    "\n",
    "# Fit the model to the training data\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = catboost_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197a00c8-e6c1-4e86-93ea-008c402fcd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ru368\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[453 119]\n",
      " [167 334]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76       572\n",
      "           1       0.74      0.67      0.70       501\n",
      "\n",
      "    accuracy                           0.73      1073\n",
      "   macro avg       0.73      0.73      0.73      1073\n",
      "weighted avg       0.73      0.73      0.73      1073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Initialize the base estimator for AdaBoost (e.g., a DecisionTree)\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Initialize the AdaBoost Classifier\n",
    "adaboost_model = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = adaboost_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0619b05b-61c5-485d-8ebf-6d6de789a023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[468 104]\n",
      " [147 354]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       572\n",
      "           1       0.77      0.71      0.74       501\n",
      "\n",
      "    accuracy                           0.77      1073\n",
      "   macro avg       0.77      0.76      0.76      1073\n",
      "weighted avg       0.77      0.77      0.77      1073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4efcaf6a-f234-4089-94e7-c3a35632cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[369 203]\n",
      " [166 335]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67       572\n",
      "           1       0.62      0.67      0.64       501\n",
      "\n",
      "    accuracy                           0.66      1073\n",
      "   macro avg       0.66      0.66      0.66      1073\n",
      "weighted avg       0.66      0.66      0.66      1073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Initialize the Naive Bayes Classifier\n",
    "naive_bayes_model = GaussianNB()\n",
    "\n",
    "# Fit the model to the training data\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = naive_bayes_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706341ba-7bf7-42fb-9cef-876a97407331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[414 158]\n",
      " [231 270]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68       572\n",
      "           1       0.63      0.54      0.58       501\n",
      "\n",
      "    accuracy                           0.64      1073\n",
      "   macro avg       0.64      0.63      0.63      1073\n",
      "weighted avg       0.64      0.64      0.63      1073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Initialize SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "# Train the model on the full training set\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
